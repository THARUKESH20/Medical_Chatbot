This project implements an intelligent healthcare chatbot using LangChain, Streamlit, and Hugging Face models. The chatbot is designed to help users ask questions related to mental health and provide informative responses based on a PDF document containing relevant information. Using LangChain, the chatbot processes a PDF document on mental health, splits the text into chunks, and creates embeddings with Hugging Face models for efficient similarity search with FAISS. It utilizes a conversational memory, allowing the chatbot to maintain a history of interactions for more personalized responses. The chatbot is built on Streamlit, providing an interactive web interface for users to query the system. The setup involves cloning the repository, setting up the environment, installing dependencies, and running the Streamlit app. The user inputs a question, and the chatbot retrieves the most relevant answers from the document based on the conversation history, delivering informative responses. This project is customizable, allowing for the integration of different pre-trained models and text-processing techniques for document-based conversational agents.


To integrate the Llama-2-7B-Chat model from Hugging Face into your GitHub repository, first download the model file llama-2-7b-chat.ggmlv3.q4_0.bin from the Hugging Face model page. Once downloaded, move the model file to the appropriate directory in your project. Use Git commands to add and commit the model to your repository by running git add path/to/llama-2-7b-chat.ggmlv3.q4_0.bin, followed by git commit -m "Add Llama-2-7B-Chat model" and git push origin main. Ensure that the model file is correctly referenced in your project, and update your README to mention the integration, including the link to download the model either from Hugging Face or from your repository if it's hosted there.
